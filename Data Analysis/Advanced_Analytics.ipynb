{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5409d6d8-70e9-43f7-9967-ba38717f4648",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.sql.functions import col, avg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# --- Setup ---\n",
    "spark.sql(\"USE CATALOG final_project\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 1: K-Means Clustering (District Risk Profiling)\n",
    "# ==============================================================================\n",
    "print(\"Starting K-Means Clustering on Districts...\")\n",
    "\n",
    "df_district = spark.read.table(\"final_project.gold.district_stats\")\n",
    "\n",
    "# Prepare features: Violent Count, Property Count, Arrest Rate\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"violent_crimes_count\", \"property_crimes_count\", \"arrest_rate\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "data_vec = assembler.transform(df_district)\n",
    "\n",
    "# Scale features (important for K-Means)\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "scalerModel = scaler.fit(data_vec)\n",
    "scaledData = scalerModel.transform(data_vec)\n",
    "\n",
    "# Train K-Means (k=3: Low Risk, Medium Risk, High Risk)\n",
    "kmeans = KMeans(featuresCol=\"scaledFeatures\", k=3, seed=1)\n",
    "model = kmeans.fit(scaledData)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(scaledData)\n",
    "print(\"Clustering complete. Cluster centers displayed below:\")\n",
    "\n",
    "centers = model.clusterCenters()\n",
    "for center in centers:\n",
    "    print(center)\n",
    "\n",
    "# Visualizing Clusters\n",
    "pdf_clusters = predictions.select(\"District\", \"violent_crimes_count\", \"property_crimes_count\", \"prediction\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=pdf_clusters, \n",
    "    x='property_crimes_count', \n",
    "    y='violent_crimes_count', \n",
    "    hue='prediction', \n",
    "    palette='deep', \n",
    "    s=100\n",
    ")\n",
    "plt.title('District Segmentation: K-Means Clustering (k=3)')\n",
    "plt.xlabel('Property Crimes')\n",
    "plt.ylabel('Violent Crimes')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ==============================================================================\n",
    "# PART 2: Hypothesis Testing (Weekend vs. Weekday Effect)\n",
    "# ==============================================================================\n",
    "print(\"Performing Statistical Hypothesis Analysis: Weekend vs Weekday...\")\n",
    "\n",
    "df_ml = spark.read.table(\"final_project.gold.ml_features\")\n",
    "\n",
    "# Calculate average crimes per hour for Weekends (1) vs Weekdays (0)\n",
    "# We aggregate by date first to get daily counts, then average by is_weekend\n",
    "stats = df_ml.groupBy(\"crime_month\", \"day_of_week\", \"is_weekend\") \\\n",
    "    .count() \\\n",
    "    .groupBy(\"is_weekend\") \\\n",
    "    .agg(avg(\"count\").alias(\"avg_daily_crimes\")) \\\n",
    "    .toPandas()\n",
    "\n",
    "print(\"Average Daily Crimes (0=Weekday, 1=Weekend):\")\n",
    "print(stats)\n",
    "\n",
    "# Visualization of distribution\n",
    "pdf_dist = df_ml.groupBy(\"crime_date\", \"is_weekend\").count().toPandas()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=pdf_dist, x='is_weekend', y='count')\n",
    "plt.title('Distribution of Daily Crime Volume: Weekday (0) vs Weekend (1)')\n",
    "plt.ylabel('Daily Crimes')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Advanced_Analytics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
